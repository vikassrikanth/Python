{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def YtDetails(url, href):\n",
    "    req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    try:\n",
    "        webpage = urlopen(req).read()\n",
    "    \n",
    "        #break\n",
    "# Creating a BeautifulSoup object of the html page for easy extraction of data.\n",
    "\n",
    "        soup = bs(webpage, 'html.parser')\n",
    "        html = soup.prettify('utf-8')\n",
    "        video_details = {}\n",
    "        other_details = {}\n",
    "\n",
    "        for span in soup.findAll('span',attrs={'class': 'watch-title'}):\n",
    "            video_details['TITLE'] = span.text.strip()\n",
    "\n",
    "        for script in soup.findAll('script',attrs={'type': 'application/ld+json'}):\n",
    "            channelDesctiption = json.loads(script.text.strip())\n",
    "            try:\n",
    "                video_details['CHANNEL_NAME'] = channelDesctiption['itemListElement'][0]['item']['name']\n",
    "            except:\n",
    "                break\n",
    "        for div in soup.findAll('div',attrs={'class': 'watch-view-count'}):\n",
    "            video_details['NUMBER_OF_VIEWS'] = div.text.strip()\n",
    "\n",
    "        for button in soup.findAll('button',attrs={'title': 'I like this'}):\n",
    "            video_details['LIKES'] = button.text.strip()\n",
    "\n",
    "        for button in soup.findAll('button',attrs={'title': 'I dislike this'}):\n",
    "            video_details['DISLIKES'] = button.text.strip()\n",
    "\n",
    "        date = []\n",
    "        for strong in soup.find_all('strong',attrs={'class': 'watch-time-text'}):\n",
    "            video_details['DATE']=strong.text.strip()\n",
    "\n",
    "        for span in soup.findAll('span',attrs={'class': 'yt-subscription-button-subscriber-count-branded-horizontal yt-subscriber-count'}):\n",
    "            video_details['NUMBER_OF_SUBSCRIPTIONS'] = span.text.strip()\n",
    "\n",
    "        hashtags = []\n",
    "        for span in soup.findAll('span',attrs={'class': 'standalone-collection-badge-renderer-text'}):\n",
    "            for a in span.findAll('a',attrs={'class': 'yt-uix-sessionlink'}):\n",
    "                hashtags.append(a.text.strip())\n",
    "        video_details['HASH_TAGS'] = hashtags\n",
    "\n",
    "        description = []\n",
    "        for p in soup.find_all('p', id='eow-description'):\n",
    "            video_details['DESCRIPTION']=p.text.strip()\n",
    "        #for div in soup.findAll('div', attrs={'class': 'style-scope ytd-expander'}):\n",
    "        #for div in soup.findAll('span',attrs={'class': 'standalone-collection-badge-renderer-text'}):\n",
    "        #    for div in soup.findAll('div', attrs={'class': 'content style-scope ytd-video-secondary-info-renderer'}):\n",
    "        #        description.append(div.text.strip())\n",
    "        #video_details['DESCRIPTION'] = description\n",
    "\n",
    "\n",
    "        with open('output_file.html', 'wb') as file:\n",
    "            file.write(html)\n",
    "        try:\n",
    "            with open('data'+href+'.json', 'w', encoding='utf8') as outfile:\n",
    "                json.dump(video_details, outfile, ensure_ascii=False,indent=4)\n",
    "\n",
    "            print ('----------Extraction of data is complete. Check json file.----------')\n",
    "        except:\n",
    "            print(\"Ad\")\n",
    "    except:\n",
    "        print('Invalid link')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recent Uploads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikas.srikanth\\Youtube\\Toys\\Ryan\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"C://Users//vikas.srikanth//Youtube//Toys//Ryan//\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "import urllib.error\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import ssl\n",
    "import json\n",
    "import ast\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import requests \n",
    "from urllib.request import Request, urlopen\n",
    "from tqdm import tqdm\n",
    "# For ignoring SSL certificate errors\n",
    "\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "# Collecting all the URLs\n",
    "base = \"https://www.youtube.com/results?search_query=\"\n",
    "\n",
    "#Enter your Search query\n",
    "search=[\"Ryan Toy review\"]\n",
    "videolist=[]\n",
    "for t in tqdm(search):\n",
    "    i=0\n",
    "    j=1\n",
    "    for j in range (1,8):\n",
    "        qstring = t\n",
    "        page=\"&page=\"\n",
    "        recent = \"&sp=CAI%253D\" #- Recent most upload date\n",
    "        viewCount=\"&sp=CAMSAhAB\" #- View count\n",
    "        #r = requests.get(base+qstring+page+str(i))\n",
    "        r = requests.get(base+qstring+recent+page+str(j))\n",
    "        page = r.text\n",
    "    #print(page)\n",
    "   \n",
    "        soup=bs(page,'html.parser')\n",
    "        vids = soup.findAll('a',attrs={'class':'yt-uix-tile-link'})\n",
    "        #print(vids)\n",
    "        #for j in range (1,3):\n",
    "        for v in vids:\n",
    "\n",
    "                tmp = 'https://www.youtube.com' + v['href']\n",
    "                #print(tmp)\n",
    "                href=v['href']\n",
    "                videolist.append(tmp)\n",
    "                print(videolist[i], i, j)\n",
    "                #i+=1\n",
    "                url = videolist[i]\n",
    "                href=re.sub('[^A-Za-z0-9]+','', href)\n",
    "                YtDetails(url, href)\n",
    "                i += 1\n",
    "                print(t)\n",
    "        #j+=1\n",
    "            \n",
    "# Making the website believe that you are accessing it using a mozilla browser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "print(len(videolist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in vids:\n",
    "            tmp = 'https://www.youtube.com' + v['href']\n",
    "            href=v['href']\n",
    "            videolist.append(tmp)\n",
    "            print(videolist[i])\n",
    "            url = videolist[i]\n",
    "            href=re.sub('[^A-Za-z0-9]+','', href)\n",
    "            YtDetails(url, href)\n",
    "            i += 1\n",
    "            print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search=[\"home decor\", \"home decor trends\", \"home decor 2019 emerging\", \"home decor DIY 2019\", \"home decor kitchen trends\",\n",
    "       \"home improvement trends\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Count Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "import urllib.error\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import ssl\n",
    "import json\n",
    "import ast\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import requests \n",
    "from urllib.request import Request, urlopen\n",
    "from tqdm import tqdm\n",
    "# For ignoring SSL certificate errors\n",
    "\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "# Collecting all the URLs\n",
    "base = \"https://www.youtube.com/results?search_query=\"\n",
    "\n",
    "#Enter your Search query\n",
    "search=[\"Fashion trends\", \"spring 2019 fashion trends\", \"emerging fashion styles\", \"2020 fashion trends\", \"children fashion trends\",\n",
    "       \"fashion trends colors\", \"NY fashion week trends\"]\n",
    "videolist=[]\n",
    "for t in tqdm(search):\n",
    "    i=0\n",
    "    qstring = t\n",
    "    page=\"&page=\"\n",
    "    recent = \"&sp=CAI%253D\" #- Recent most upload date\n",
    "    viewCount=\"&sp=CAMSAhAB\" #- View count\n",
    "    #r = requests.get(base+qstring+page+str(i))\n",
    "    r = requests.get(base+qstring+viewCount)\n",
    "    page = r.text\n",
    "   \n",
    "    soup=bs(page,'html.parser')\n",
    "    vids = soup.findAll('a',attrs={'class':'yt-uix-tile-link'})\n",
    "    \n",
    "    #for i in range (0,len(search)):\n",
    "    for v in vids:\n",
    "        tmp = 'https://www.youtube.com' + v['href']\n",
    "        href=v['href']\n",
    "        videolist.append(tmp)\n",
    "        print(videolist[i])\n",
    "        url = videolist[i]\n",
    "        href=re.sub('[^A-Za-z0-9]+','', href)\n",
    "        YtDetails(url, href)\n",
    "        i += 1\n",
    "        print(t)\n",
    "\n",
    "# Making the website believe that you are accessing it using a mozilla browser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "os.chdir(\"C:\\\\Users\\\\vikas.srikanth\\\\Youtube\\\\Home Decor\")\n",
    "print(os.getcwd())\n",
    "# Without a filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "import urllib.error\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import ssl\n",
    "import json\n",
    "import ast\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import requests \n",
    "from urllib.request import Request, urlopen\n",
    "from tqdm import tqdm\n",
    "# For ignoring SSL certificate errors\n",
    "\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "# Collecting all the URLs\n",
    "base = \"https://www.youtube.com/results?search_query=\"\n",
    "\n",
    "#Enter your Search query\n",
    "search=[\"Fashion trends\", \"spring 2019 fashion trends\", \"emerging fashion styles\", \"2020 fashion trends\", \"children fashion trends\",\n",
    "       \"fashion trends colors\", \"NY fashion week trends\"]\n",
    "videolist=[]\n",
    "for t in tqdm(search):\n",
    "    i=0\n",
    "    qstring = t\n",
    "    page=\"&page=\"\n",
    "    #recent = \"&sp=CAI%253D\" #- Recent most upload date\n",
    "    #viewCount=\"&sp=CAMSAhAB\" #- View count\n",
    "    #r = requests.get(base+qstring+page+str(i))\n",
    "    r = requests.get(base+qstring)\n",
    "    page = r.text\n",
    "   \n",
    "    soup=bs(page,'html.parser')\n",
    "    vids = soup.findAll('a',attrs={'class':'yt-uix-tile-link'})\n",
    "    \n",
    "    #for i in range (0,len(search)):\n",
    "    for v in vids:\n",
    "        tmp = 'https://www.youtube.com' + v['href']\n",
    "        href=v['href']\n",
    "        videolist.append(tmp)\n",
    "        print(videolist[i])\n",
    "        url = videolist[i]\n",
    "        href=re.sub('[^A-Za-z0-9]+','', href)\n",
    "        YtDetails(url, href)\n",
    "        i += 1\n",
    "        print(t)\n",
    "\n",
    "# Making the website believe that you are accessing it using a mozilla browser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(videolist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
